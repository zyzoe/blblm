---
title: "Vignette for package `blblm`"
author: "Yi Zhu"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette for package `blblm`}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(blblm)
```

# The Package `blblm`: A Brief Introduction

Bag of Little Bootstraps, also known as BLB, is a resampling method devised by Kleiner et al.(2014). Bootstrapping uses random sampling with replacement for users to perform inference about a sample from resampled data. However, traditional bootstrapping invovles large dataset, which could be computationally demanding. Therefore, Bag of Little Bootstraps is introduced as a new procedure that combines the features of subsampling and bootstrapping. Compare to the bootstrap, BLB yields a robust, computationally efficient means of assessing the quality of estimators. 

Ref: [A Scalable Bootstrap for Massive Data](https://arxiv.org/abs/1112.5016)

- This package includes two functions:
  - `blblm()`  Bag of Little Bootstraps for linear regression
  - `blbglm()` Bag of Little Bootstraps for generalized linear model
  
## `blblm()` function
`blblm()` outputs the simulated bootsrap data fitting a linear regression model

- Parameters:
  - `formula` a formula fitting a linear regression model
  - `data` dataset for the model
  - `m` number of subsets
  - `B` number of simulations
  - `parallel` a logical operator, T for parallelization
  - `select_names` character list for file names

In default setting, blblm does not use parallelization, only one CPU is used in the algorithm. Also, this function loads the whole dataset in the main process. When select `parallel = TRUE`, users can use parallelization to use more than one CPUs. When specify select_names, users can selectively load a list of file of datasets.

- Functions called in `blblm()`:
  - `split_data()`: split data into m parts of approximated equal sizes
  - `prepare_files()`: Prepare the subfiles, select the specific files
  - `lm_each_subsample()`: compute the estimates

```{r}
blblm <- function(formula, data, m = 10, B = 5000,parallel = FALSE,select_names = NULL) {
  # When user do not select specific sub files
  if (is.null(select_names)){data_list <- split_data(data, m)}
  # When user select specific sub files, provided a list of file names
  else{
    data_list <- prepare_files(data,m,select_names)
  }
  # When user set parallel = TRUE, use parallelization
  if (parallel){
    cl <- makeCluster(detectCores()) # Detect cores and make cluster
    clusterExport(cl=cl, varlist=c("lm_each_boot","lm1","blbcoef","blbsigma"),
                  envir=environment()) # Export the functions for processing
    estimates <- parLapply(cl,data_list,
                           lm_each_subsample, formula = formula, n = nrow(data), B = B)
    stopCluster(cl)}
  # When user set parallel = FALSE(default), don't use parallelization
  else{
  estimates <- map(
    data_list,
    ~ lm_each_subsample(formula = formula, data = ., n = nrow(data), B = B))}
  res <- list(estimates = estimates, formula = formula)
  class(res) <- "blblm"
  invisible(res)
}
```


## Functions for dataset processing
### `split_data()` function

Split data into m parts of approximated equal sizes. Return a list of subsets in the form of data frame. 

```{r}
split_data <- function(data, m) {
  idx <- sample.int(m, nrow(data), replace = TRUE)
  data %>% split(idx)
}
```

### `prepare_files()` function

This function includes two parts. First, it takes the dataset and generates the subfiles. Then it takes a character list of user specified file names and reads in the content of csv files. In reality, users would have a list of folder of datasets. In that case, this function only reads the selected csv files (the file generating section in the comment for reference). 

```{r}
prepare_files <- function(data,m,select_names){
  # Prepare the sub files
  #data <- split_data(data, m)
  #dir.create("files", showWarnings = FALSE)
  #set.seed(141)

  #for(i in names(data)){
  #  write_csv(data[[i]], file.path("files", paste0(i,".csv")))}

  ### Generated test files stored in folder called `files`
  file_names <- file.path("files", select_names)
  # Read the selected files
  data_list <- file_names %>% map(read_csv)
}
```

## Functions for Bag of Little Bootstraps: linear regression
### `lm_each_subsample()` function

Take the output from `lm_each_boot()`, replicate B times, compute the estimates.

```{r}
lm_each_subsample <- function(formula, data, n, B) {
  replicate(B, lm_each_boot(formula, data, n), simplify = FALSE)
}
```


### `lm_each_boot()` function

Take the output from `lm1()`, add the weights for the weighted regression model, compute the regression estimates for a blb dataset.

```{r}
lm_each_boot <- function(formula, data, n) {
  freqs <- rmultinom(1, n, rep(1, nrow(data)))# weights for weighted regression model
  lm1(formula, data, freqs)
}
```

### `lm1()` function

Fit a linear regression model according to the input, compute the coefficients from fit. 

```{r}
lm1 <- function(formula, data, freqs) {
  # drop the original closure of formula,
  # otherwise the formula will pick a wront variable from the global scope.
  environment(formula) <- environment()
  fit <- lm(formula, data, weights = freqs)
  list(coef = blbcoef(fit), sigma = blbsigma(fit))
}
```



## `blbglm()` function
`blbglm()` outputs the simulated bootsrap data fitting a generalized linear model

- Parameters:
  - `formula` a formula fitting a generalized linear model
  - `data` dataset for the model
  - `m` number of subsets
  - `B` number of simulations
  - `parallel` a logical operator, T for parallelization
  - `select_names` character list for file names
  - `family` family type for models, such as binomial, gaussian, gamma etc.
  
`blbglm()` is very similar to `blblm()`. For `blbglm()`, we need to specify the family type for `glm()` funtion. Check [glm()](https://www.statmethods.net/advstats/glm.html) for more information. 

```{r}
blbglm <- function(formula, data, m = 10, B = 5000,parallel = FALSE,select_names = NULL,family) {
  # When user do not select specific sub files
  if (is.null(select_names)){data_list <- split_data(data, m)}
  # When user select specific sub files, provided a list of file names
  else{
    data_list <- prepare_files(data,m,select_names)
  }
  # When user set parallel = TRUE, use parallelization
  if (parallel){
    cl <- makeCluster(detectCores()) # Detect cores and make cluster
    clusterExport(cl=cl, varlist=c("glm_each_boot","glm1","blbcoef","blbsigma"),
                  envir=environment()) # Export the functions for processing
    estimates <- parLapply(cl,data_list,
                           glm_each_subsample, formula = formula, n = nrow(data), B = B,family = family)
    stopCluster(cl)}
  # When user set parallel = FALSE(default), don't use parallelization
  else{
    estimates <- map(
      data_list,
      ~ glm_each_subsample(formula = formula, data = ., n = nrow(data), B = B,family = family))}
  res <- list(estimates = estimates, formula = formula)
  class(res) <- "blblm"
  invisible(res)
}
```

## Functions for Bag of Little Bootstraps: generalized linear model

Note that all functions in this section are similar to those for linear regression, but they all pass a parameter `family` for `glm()` to specify the family type. 

### `glm_each_subsample()` function

Take the output from `glm_each_boot()`, replicate B times, compute the estimates.

```{r}
glm_each_subsample <- function(formula, data, n, B,family) {
  replicate(B, glm_each_boot(formula, data, n,family), simplify = FALSE)
}
```


### `glm_each_boot()` function

Take the output from `glm1()`, add the weights for the weighted model, compute the regression estimates for a blb dataset.

```{r}
glm_each_boot <- function(formula, data, n,family) {
  freqs <- rmultinom(1, n, rep(1, nrow(data)))# Weights for weighted regression model
  glm1(formula, data, freqs,family)
}
```

### `glm1()` function

Fit a selected linear model according to the input, compute the coefficients from fit. 

```{r}
glm1 <- function(formula, data, freqs,family) {
  # drop the original closure of formula,
  # otherwise the formula will pick a wront variable from the global scope.
  environment(formula) <- environment()
  fit <- glm(formula,family = family, data = data, weights = freqs)
  list(coef = blbcoef(fit), sigma = blbsigma(fit))
}
```

## Functions for inference

This section includes the following functions that allow users to check the estimators: 
- `coef()`: example `coef(fit)`
- `confint()`: example `confint(fit, c("wt", "hp"))`
- `sigma()`: example `sigma(fit, confidence = TRUE)`
- `predict()`: example: `predict(fit, data.frame(wt = c(2.5, 3), hp = c(150, 170)), confidence = TRUE)`

```{r}
# compute the coefficients from fit
blbcoef <- function(fit) {
  coef(fit)
}
# compute sigma from fit
blbsigma <- function(fit) {
  p <- fit$rank
  y <- model.extract(fit$model, "response")
  e <- fitted(fit) - y
  w <- fit$weights
  sqrt(sum(w * (e^2)) / (sum(w) - p))
}


print.blblm <- function(x, ...) {
  cat("blblm model:", capture.output(x$formula))
  cat("\n")
}


#' @export
#' @method sigma blblm
sigma.blblm <- function(object, confidence = FALSE, level = 0.95, ...) {
  est <- object$estimates
  sigma <- mean(map_dbl(est, ~ mean(map_dbl(., "sigma"))))
  if (confidence) {
    alpha <- 1 - 0.95
    limits <- est %>%
      map_mean(~ quantile(map_dbl(., "sigma"), c(alpha / 2, 1 - alpha / 2))) %>%
      set_names(NULL)
    return(c(sigma = sigma, lwr = limits[1], upr = limits[2]))
  } else {
    return(sigma)
  }
}

coef.blblm <- function(object, ...) {
  est <- object$estimates
  map_mean(est, ~ map_cbind(., "coef") %>% rowMeans())
}

confint.blblm <- function(object, parm = NULL, level = 0.95, ...) {
  if (is.null(parm)) {
    parm <- attr(terms(object$formula), "term.labels")
  }
  alpha <- 1 - level
  est <- object$estimates
  out <- map_rbind(parm, function(p) {
    map_mean(est, ~ map_dbl(., list("coef", p)) %>% quantile(c(alpha / 2, 1 - alpha / 2)))
  })
  if (is.vector(out)) {
    out <- as.matrix(t(out))
  }
  dimnames(out)[[1]] <- parm
  out
}

predict.blblm <- function(object, new_data, confidence = FALSE, level = 0.95, ...) {
  est <- object$estimates
  X <- model.matrix(reformulate(attr(terms(object$formula), "term.labels")), new_data)
  if (confidence) {
    map_mean(est, ~ map_cbind(., ~ X %*% .$coef) %>%
      apply(1, mean_lwr_upr, level = level) %>%
      t())
  } else {
    map_mean(est, ~ map_cbind(., ~ X %*% .$coef) %>% rowMeans())
  }
}


mean_lwr_upr <- function(x, level = 0.95) {
  alpha <- 1 - level
  c(fit = mean(x), quantile(x, c(alpha / 2, 1 - alpha / 2)) %>% set_names(c("lwr", "upr")))
}

map_mean <- function(.x, .f, ...) {
  (map(.x, .f, ...) %>% reduce(`+`)) / length(.x)
}

map_cbind <- function(.x, .f, ...) {
  map(.x, .f, ...) %>% reduce(cbind)
}

map_rbind <- function(.x, .f, ...) {
  map(.x, .f, ...) %>% reduce(rbind)
}
```
